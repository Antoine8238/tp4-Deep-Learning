# TP4 : Advanced Vision, Segmentation, and 3D Data

##  Description

ImplÃ©mentation de l'architecture U-Net pour la segmentation sÃ©mantique d'images mÃ©dicales et introduction aux convolutions 3D pour donnÃ©es volumÃ©triques. Ce projet applique les meilleures pratiques MLOps avec tracking des expÃ©riences via MLflow.

**Module :** Deep Learning Engineering - 5GI  
**Ã‰cole :** ENSPY, UniversitÃ© de YaoundÃ© I  
**AnnÃ©e :** 2024-2025

---

##  Objectifs

-  MaÃ®triser la segmentation sÃ©mantique avec U-Net
-  ImplÃ©menter des mÃ©triques spÃ©cifiques (IoU, Dice Coefficient)
-  Appliquer les pratiques MLOps (experiment tracking avec MLflow)
-  Comprendre les convolutions 3D pour donnÃ©es volumÃ©triques
- GÃ©rer les dÃ©fis des donnÃ©es mÃ©dicales (dÃ©sÃ©quilibre, taille limitÃ©e)

---

##  Structure du Projet

```
tp4-segmentation/
â”œâ”€â”€ unet.py       # Architecture U-Net complÃ¨te
â”œâ”€â”€ metrics.py    # MÃ©triques de segmentation (Dice, IoU)
â”œâ”€â”€ train.py        # EntraÃ®nement avec MLflow tracking
â”œâ”€â”€ conv3d.py       # Convolutions 3D pour donnÃ©es volumÃ©triques
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python


---

##  Installation

### PrÃ©requis

- Python 3.8+
- pip

### Installation des dÃ©pendances

```bash
pip install -r requirements.txt
```

**Contenu de `requirements.txt` :**
```
tensorflow>=2.13.0
mlflow>=2.8.0
scikit-learn>=1.3.0
numpy>=1.24.0
```

---

##  Utilisation

### Exercice 2.1 : Architecture U-Net

Construction de l'architecture U-Net avec skip connections.

```bash
python exercice_2_1_unet.py
```

**Sortie attendue :**
- RÃ©sumÃ© de l'architecture
- Nombre de paramÃ¨tres
- Dimensions input/output

### Exercice 2.2 : MÃ©triques de Segmentation

ImplÃ©mentation et test des mÃ©triques Dice Coefficient et IoU.

```bash
python exercice_2_2_metrics.py
```

**Sortie attendue :**
- Tests sur donnÃ©es synthÃ©tiques
- Comparaison Dice vs IoU
- Validation des formules

### Exercice 2.3 : EntraÃ®nement avec MLflow

GÃ©nÃ©ration de donnÃ©es synthÃ©tiques et entraÃ®nement du modÃ¨le U-Net.

```bash
python exercice_2_train.py
```

**Sortie attendue :**
- GÃ©nÃ©ration de 200 images synthÃ©tiques
- EntraÃ®nement pendant 30 epochs (avec early stopping)
- MÃ©triques finales (Dice, IoU, Loss)
- Tracking automatique dans MLflow

### Exercice 3 : Convolutions 3D

ImplÃ©mentation d'un bloc Conv3D pour donnÃ©es volumÃ©triques.

```bash
python exercice_3_conv3d.py
```

**Sortie attendue :**
- Architecture Conv3D
- Simulation d'entraÃ®nement
- Tracking MLflow

---

##  Visualisation des RÃ©sultats (MLflow)

AprÃ¨s avoir exÃ©cutÃ© les scripts, visualisez les expÃ©riences :

```bash
mlflow ui
```

Puis ouvrez dans votre navigateur : **http://localhost:5000**

### Ce que vous verrez dans MLflow :

- **ExpÃ©riences :** Toutes les runs trackÃ©es
- **ParamÃ¨tres :** Architecture, optimizer, loss function, etc.
- **MÃ©triques :** Courbes de convergence (Dice, IoU, Loss)
- **Artefacts :** Configuration des modÃ¨les (JSON)

---

##  Architecture U-Net

```
Input (128Ã—128Ã—1)
      â†“
[Conv Block 32] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â†“ MaxPool (64Ã—64)              â”‚
[Conv Block 64] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
      â†“ MaxPool (32Ã—32)        â”‚     â”‚
[Conv Block 128] â”€â”€â”€â”€â”€â”€â”€â”     â”‚     â”‚
      â†“ MaxPool (16Ã—16) â”‚     â”‚     â”‚
[Conv Block 256]        â”‚     â”‚     â”‚
      â†“ Upsample         â”‚     â”‚     â”‚
[Concat + Conv 128] â†â”€â”€â”€â”˜     â”‚     â”‚  Skip Connections
      â†“ Upsample               â”‚     â”‚
[Concat + Conv 64]  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
      â†“ Upsample                     â”‚
[Concat + Conv 32]  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
Output (128Ã—128Ã—1)
```

**CaractÃ©ristiques :**
- 4 niveaux (encoder + decoder)
- Skip connections par concatenation
- Activation sigmoid en sortie (segmentation binaire)
- ~X,XXX,XXX paramÃ¨tres

---

##  MÃ©triques ImplÃ©mentÃ©es

### Dice Coefficient

```
Dice = 2Â·|A âˆ© B| / (|A| + |B|)
```

- **Plage :** [0, 1] (1 = parfait)
- **Usage :** MÃ©trique principale en imagerie mÃ©dicale
- **Avantage :** TolÃ©rant aux donnÃ©es dÃ©sÃ©quilibrÃ©es

### IoU (Intersection over Union)

```
IoU = |A âˆ© B| / |A âˆª B|
```

- **Plage :** [0, 1] (1 = parfait)
- **Usage :** Segmentation gÃ©nÃ©rale
- **Avantage :** Plus strict que Dice

### Relation entre Dice et IoU

```
Dice = 2Â·IoU / (1 + IoU)
```

**Exemple :**
- IoU = 0.5 â†’ Dice = 0.667
- IoU = 0.8 â†’ Dice = 0.889

---

## Convolutions 3D

### DiffÃ©rence Conv2D vs Conv3D

| Aspect | Conv2D | Conv3D |
|--------|--------|--------|
| **Kernel** | kÃ—k | kÃ—kÃ—k |
| **ParamÃ¨tres (k=3)** | 9 | 27 |
| **Mouvement** | Sur (H, W) | Sur (D, H, W) |
| **Input** | HÃ—WÃ—C | DÃ—HÃ—WÃ—C |

### DÃ©fis Computationnels

- **MÃ©moire :** ~27Ã— plus coÃ»teux qu'un Conv2D (kernel 3Ã—3Ã—3)
- **Solutions :**
  - RÃ©duire la taille du kernel (3Ã—3Ã—3 â†’ 2Ã—2Ã—2)
  - Moins de filtres par couche
  - RÃ©duire la profondeur D (moins de slices)
  - Mixed precision training (float16)

---

## RÃ©sultats Attendus

### U-Net Training

| MÃ©trique | Valeur |
|----------|--------|
| **Dice Coefficient** | > 0.85 |
| **IoU** | > 0.75 |
| **Loss** | < 0.20 |
| **Epochs** | ~15-25 (avec early stopping) |

*Remplacez par vos rÃ©sultats rÃ©els aprÃ¨s entraÃ®nement*

---

##  Configuration MLflow

### Convention de Nommage

Format : `{Architecture}_{Loss}_{Optimizer}`

**Exemples :**
- `UNet_DiceLoss_Adam`
- `UNet_CombinedLoss_SGD`
- `Conv3D_Baseline`

### HyperparamÃ¨tres LoggÃ©s

- Architecture
- Optimizer (type + learning rate)
- Loss function
- Batch size
- Nombre d'epochs

### MÃ©triques LoggÃ©es

- Dice Coefficient (par epoch)
- IoU (par epoch)
- Loss (train + validation)
- MÃ©triques finales

---

##  Questions ThÃ©oriques (RÃ©ponses dans le Rapport)

1. **Output de segmentation sÃ©mantique :** Dimension et nature du tenseur de sortie
2. **Skip connections U-Net vs ResNet :** DiffÃ©rence et rÃ´le du decoder
3. **Loss functions pour donnÃ©es mÃ©dicales :** Pourquoi cross-entropy est inadÃ©quate
4. **Conv3D vs Conv2D :** DiffÃ©rences et nÃ©cessitÃ© pour donnÃ©es volumÃ©triques
5. **Trade-offs Conv3D :** Gestion des contraintes mÃ©moire

---

##  Technologies UtilisÃ©es

- **TensorFlow/Keras** : Framework Deep Learning
- **MLflow** : Experiment tracking et MLOps
- **NumPy** : Manipulation de donnÃ©es
- **Scikit-learn** : Train/test split
- **Python 3.8+** : Langage de programmation

---

##  RÃ©fÃ©rences

1. Ronneberger, O., et al. (2015). **U-Net: Convolutional Networks for Biomedical Image Segmentation.** *MICCAI*.
2. Milletari, F., et al. (2016). **V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation.** *3DV*.
3. Sudre, C. H., et al. (2017). **Generalised Dice overlap as a deep learning loss function.** *DLMIA*.

---

## ðŸ‘¥ Auteur

**[Antoine Emmanuel ESSOMBA ESSOMBA]**  
Matricule : [23p750]  
Email : [essombantoine385@gmail.com]

---

## ðŸ“„ Licence

Ce projet est rÃ©alisÃ© dans le cadre du module Deep Learning Engineering Ã  l'ENSPY.

---




---

##  Support

Pour toute question ou problÃ¨me :
1. Consultez le rapport PDF pour les dÃ©tails thÃ©oriques
2. VÃ©rifiez les logs MLflow pour les rÃ©sultats d'expÃ©riences
3. Ouvrez une issue sur ce repository

---

**DerniÃ¨re mise Ã  jour :** Novembre 2025
